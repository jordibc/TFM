#!/usr/bin/env bash
#SBATCH --job-name Humann3               # Name for your job
#SBATCH --partition=bigmem,long,medium   # Partition to submit
#SBATCH --time=1-00:00:00                # total run time limit in HH:MM:SS
#SBATCH --mail-type=end                  # send email when job ends
#SBATCH --mail-user=luciamartinfernandez99@gmail.com # this is the email you wish to be notified at
#SBATCH --mem=40GB                       # Reserve X GB RAM for the job
#SBATCH -c 5
#SBATCH --output=logs/humann3-%a.%A.out # STDOUT file
#SBATCH --error=logs/humann3-%a.%A.err  # STDERR file
#SBATCH --array=0-116


# Remember to create logs directory in terminal
# mkdir logs


#HUMANn3: 1) identifying community species with MetaPhlAn (ChocoPhlAn database), 2) mapping reads to community pangenomes (with bowtie2), and 3) aligning unmapped reads to a protein database (UniRef90) with DIAMOND.

## INSTALL HUMAnN3: 
#Installing with pip
#conda create --name biobakery3 python=3.7
#conda activate biobakery3
#pip install humann
#pip install metaphlan
#metaphlan --install  ## install bowtie2 index


# Activate conda environment
# conda activate biobakery3


#Download the databases

#humann_databases --download chocophlan full /home/sbodi/miniconda3/envs/biobakery3/lib/python3.7/site-packages/humann/data --update-config yes
#humann_databases --download uniref uniref90_diamond /home/sbodi/miniconda3/envs/biobakery3/lib/python3.7/site-packages/humann/data --update-config yes
#humann_databases --download utility_mapping full /home/sbodi/miniconda3/envs/biobakery3/lib/python3.7/site-packages/humann/data --update-config yes



# Concatenate trimmed fastq files prior to HUMANn3 execution with pair-end reads
# cat ../00-raw_reads/samples_id.txt | xargs -I % echo "mkdir -p concatenate_fastq_trimmo; cat /home/lmartin/SRV_RyC/02-trimmomatic/%_R1.clean_qc_pair.fastq /home/lmartin/SRV_RyC/02-trimmomatic/%_R2.clean_qc_pair.fastq > concatenate_fastq_trimmo/merge_%.fq">sample_merge_trimmo.sh 


## Running HumanN3

# Create variables
names=($(cat ../00-raw_reads/samples_id.txt))


humann --input concatenate_fastq_trimmo/merge_${names[${SLURM_ARRAY_TASK_ID}]}.fq --nucleotide-database /home/lmartin/miniconda3/envs/ShotGun/lib/python3.7/site-packages/humann/data/chocophlan --protein-database /home/lmartin/miniconda3/envs/ShotGun/lib/python3.7/site-packages/humann/data/uniref --output hmn3_output/

# with unipathway instead of metacyc as reference pathway database
# humann --input concatenate_fastq_trimmo/merge_${names[${SLURM_ARRAY_TASK_ID}]}.fq --nucleotide-database /home/lmartin/miniconda3/envs/ShotGun/lib/python3.7/site-packages/humann/data/chocophlan --protein-database /home/lmartin/miniconda3/envs/ShotGun/lib/python3.7/site-packages/humann/data/uniref --pathways unipathway --output hmn3_output_unipathway --threads 5


# Additional scripts to modify output. Run directly on terminal

# humann_join_tables -i hmn3_output -o hmn3_genefamilies.tsv --file_name genefamilies

# humann_join_tables -i hmn3_output -o hmn3_pathcoverage.tsv --file_name pathcoverage

# humann_join_tables -i hmn3_output -o hmn3_pathabundance.tsv --file_name pathabundance_relab

# humann_renorm_table -i hmn3_genefamilies.tsv -o hmn3_genefamilies-cpm.tsv --units cpm

# humann_renorm_table -i hmn3_output/merge_${names[${SLURM_ARRAY_TASK_ID}]}_genefamilies.tsv --units relab -o renorm_output/merge_${names[${SLURM_ARRAY_TASK_ID}]}_renorm.tsv 
 
# humann_regroup_table -i renorm_output/merge_${names[${SLURM_ARRAY_TASK_ID}]}_renorm.tsv --custom /home/sbodi/miniconda3/envs/biobakery3/lib/python3.7/site-packages/humann/data/utility_mapping/map_ko_uniref90.txt.gz -o ko_output/merge_${names[${SLURM_ARRAY_TASK_ID}]}_ko.tsv  

# humann_regroup_table -i hmn3_output/merge_${names[${SLURM_ARRAY_TASK_ID}]}_genefamilies.tsv --custom /home/sbodi/miniconda3/envs/biobakery3/lib/python3.7/site-packages/humann/data/utility_mapping/map_ko_uniref90.txt.gz -o ko_output_rpkm/merge_${names[${SLURM_ARRAY_TASK_ID}]}_ko.tsv  

# humann_regroup_table -i renorm_output/merge_${names[${SLURM_ARRAY_TASK_ID}]}_renorm.tsv --custom /home/sbodi/miniconda3/envs/biobakery3/lib/python3.7/site-packages/humann/data/utility_mapping/map_eggnog_uniref90.txt.gz -o cog_output/merge_${names[${SLURM_ARRAY_TASK_ID}]}_cog.tsv

# humann_regroup_table -i hmn3_output/merge_${names[${SLURM_ARRAY_TASK_ID}]}_genefamilies.tsv --custom /home/sbodi/miniconda3/envs/biobakery3/lib/python3.7/site-packages/humann/data/utility_mapping/map_eggnog_uniref90.txt.gz -o cog_output_rpkm/merge_${names[${SLURM_ARRAY_TASK_ID}]}_cog.tsv
